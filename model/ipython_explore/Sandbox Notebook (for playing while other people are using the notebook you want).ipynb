{
 "metadata": {
  "name": "Sandbox Notebook (for playing while other people are using the notebook you want)"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "from scipy import stats\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "import os\n",
      "import psycopg2\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "# Fetch all records for a single station (tfl_id == 5)\n",
      "conn = psycopg2.connect(\"dbname=\"+os.environ.get('dbname')+\" user=\"+os.environ.get('dbuser')+ \" host=\"+os.environ.get('dburl'))\n",
      "\n",
      "cur = conn.cursor()\n",
      "\n",
      "# Executes a SQL command\n",
      "# This SQL command selects all rows from the boston database where the station ID is 5\n",
      "cur.execute(\"SELECT * FROM bike_ind_washingtondc WHERE tfl_id = 104;\")\n",
      "\n",
      "# Fetches all rows in the table output of the SQL query. \n",
      "# Remember to assign to a variable because we can only use fetchall() once for each SQL query.\n",
      "boston_5 = cur.fetchall()\n",
      "\n",
      "# Note that we cannot directly print boston_5. In order to view portions of it, we can use boston_5.head() [see below]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fetch all records for a single station (tfl_id == 5)\n",
      "conn = psycopg2.connect(\"dbname=\"+os.environ.get('dbname')+\" user=\"+os.environ.get('dbuser')+ \" host=\"+os.environ.get('dburl'))\n",
      "\n",
      "cur = conn.cursor()\n",
      "\n",
      "# Executes a SQL command\n",
      "# This SQL command selects all rows from the boston database where the station ID is 5\n",
      "cur.execute(\"SELECT * FROM bike_ind_washingtondc INNER JOIN weather_washingtondc ON (date_part('year',bike_ind_washingtondc.timestamp)=date_part('year',weather_washingtondc.time) AND date_part('month',bike_ind_washingtondc.timestamp)=date_part('month',weather_washingtondc.time) AND date_part('day', bike_ind_washingtondc.timestamp) = date_part('day', weather_washingtondc.time) AND date_part('hour', bike_ind_washingtondc.timestamp) = date_part('hour', weather_washingtondc.time)) WHERE bike_ind_washingtondc.tfl_id = 17;\")\n",
      "\n",
      "# Fetches all rows in the table output of the SQL query. \n",
      "# Remember to assign to a variable because we can only use fetchall() once for each SQL query.\n",
      "dc_17_plus_weather = cur.fetchall()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_df = pd.DataFrame.from_records(boston_5, columns = [\"station_id\", \"bikes_available\", \"slots_available\", \"bikes_timestamp\"], index = [\"bikes_timestamp\"])\n",
      "station_df[\"sum\"] = station_df[\"bikes_available\"] + station_df[\"slots_available\"]\n",
      "print station_df[\"sum\"].value_counts()\n",
      "print station_df[\"bikes_available\"].value_counts()\n",
      "print station_df[\"slots_available\"].value_counts()\n",
      "print station_df[station_df[\"sum\"] > 30].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "25    509549\n",
        "0     137040\n",
        "24     79579\n",
        "23     14928\n",
        "22      5280\n",
        "21      1100\n",
        "20        38\n",
        "17        20\n",
        "13        15\n",
        "6          3\n",
        "dtype: int64\n",
        "0     160337\n",
        "4      44223\n",
        "3      40973\n",
        "6      39872\n",
        "5      38949\n",
        "2      36922\n",
        "7      34972\n",
        "1      33711\n",
        "8      30775\n",
        "9      29815\n",
        "10     24915\n",
        "12     22354\n",
        "11     20580\n",
        "13     19311\n",
        "15     18758\n",
        "14     17861\n",
        "16     17036\n",
        "17     16534\n",
        "19     14968\n",
        "18     13978\n",
        "20     13465\n",
        "21     12257\n",
        "22     11669\n",
        "24     11667\n",
        "23     11066\n",
        "25     10584\n",
        "dtype: int64\n",
        "0     151441\n",
        "21     44585\n",
        "22     41689\n",
        "19     40448\n",
        "20     38865\n",
        "23     36489\n",
        "18     34549\n",
        "16     31220\n",
        "24     31137\n",
        "17     30341\n",
        "15     24816\n",
        "13     22732\n",
        "14     21263\n",
        "12     19568\n",
        "9      18898\n",
        "25     18410\n",
        "10     17930\n",
        "11     17746\n",
        "8      15526\n",
        "7      15037\n",
        "6      14431\n",
        "5      14171\n",
        "4      12596\n",
        "3      11704\n",
        "1      10985\n",
        "2      10975\n",
        "dtype: int64\n",
        "Empty DataFrame\n",
        "Columns: [station_id, bikes_available, slots_available, sum]\n",
        "Index: []"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Converts python list of tuples containing data to a pandas dataframe, and renames the columns.\n",
      "# \n",
      "# Set timezone\n",
      "timezone = 'US/Eastern'\n",
      " \n",
      "# Import data and set index to be timestamp\n",
      "boston_5_df = pd.DataFrame.from_records(boston_5, columns = [\"station_id\", \"bikes_available\", \"slots_available\", \"timestamp\"], index = [\"timestamp\"])\n",
      "\n",
      "boston_5_df.index = boston_5_df.index.tz_localize('UTC').tz_convert(timezone)\n",
      "\n",
      "#put all data into 2 minute buckets, since some data was collected every 2 minutes and some every minute\n",
      "boston_5_bucketed = boston_5_df.resample('15MIN')\n",
      "\n",
      "# Group by minute value (i.e. how many minutes have occured since midnight)\n",
      "#boston_5_annual_groups = boston_5_bucketed.groupby(boston_5_bucketed.index.map(lambda t: 60*t.hour + t.minute))\n",
      "\n",
      "# Take the mean over each minute-since-midnight group\n",
      "#boston_5_annual_averages = boston_5_annual_groups.mean()\n",
      "\n",
      "print boston_5_bucketed.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           station_id  bikes_available  slots_available\n",
        "timestamp                                                              \n",
        "2011-07-28 07:45:00-04:00           5                0               15\n",
        "2011-07-28 08:00:00-04:00           5                0               15\n",
        "2011-07-28 08:15:00-04:00           5                0               15\n",
        "2011-07-28 08:30:00-04:00           5                0               15\n",
        "2011-07-28 08:45:00-04:00           5                0               15\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Converts python list of tuples containing data to a pandas dataframe, and renames the columns.\n",
      "# \n",
      "# Set timezone\n",
      "timezone = 'US/Eastern'\n",
      " \n",
      "# Import data and set index to be timestamp\n",
      "dc_17_df = pd.DataFrame.from_records(dc_17_plus_weather, columns = [\"station_id\", \"bikes_available\", \"slots_available\", \"bikes_timestamp\", \"weather_timestamp\", \"summary\", \"precipintensity\", \"precipprob\", \"preciptype\", \"precipaccumulation\", \"temperature\"], index = [\"bikes_timestamp\"])\n",
      "\n",
      "dc_17_df.index = dc_17_df.index.tz_localize('UTC').tz_convert(timezone)\n",
      "dc_17_df[\"weather_timestamp\"] = dc_17_df.ix[:,\"weather_timestamp\"].tz_convert(timezone)\n",
      "\n",
      "#put all data into 2 minute buckets, since some data was collected every 2 minutes and some every minute\n",
      "dc_17_bucketed = dc_17_df.resample('15MIN', how = 'max')\n",
      "\n",
      "# Group by minute value (i.e. how many minutes have occured since midnight)\n",
      "#boston_5_annual_groups = boston_5_bucketed.groupby(boston_5_bucketed.index.map(lambda t: 60*t.hour + t.minute))\n",
      "\n",
      "# Take the mean over each minute-since-midnight group\n",
      "#boston_5_annual_averages = boston_5_annual_groups.mean()\n",
      "\n",
      "print dc_17_df.ix[1:20,]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           station_id  bikes_available  slots_available  \\\n",
        "bikes_timestamp                                                           \n",
        "2010-10-06 12:40:02-04:00          17                3               12   \n",
        "2010-10-06 12:44:01-04:00          17                3               12   \n",
        "2010-10-06 12:52:02-04:00          17                3               12   \n",
        "2010-10-06 12:54:01-04:00          17                3               12   \n",
        "2010-10-06 12:46:01-04:00          17                3               12   \n",
        "2010-10-06 12:56:02-04:00          17                3               12   \n",
        "2010-10-06 12:58:02-04:00          17                3               12   \n",
        "2010-10-06 12:42:02-04:00          17                3               12   \n",
        "2010-10-06 12:48:02-04:00          17                3               12   \n",
        "2010-10-06 12:50:01-04:00          17                3               12   \n",
        "2010-10-06 13:08:02-04:00          17                2               13   \n",
        "2010-10-06 13:40:01-04:00          17                1               14   \n",
        "2010-10-06 13:42:02-04:00          17                1               14   \n",
        "2010-10-06 13:10:01-04:00          17                2               13   \n",
        "2010-10-06 13:44:02-04:00          17                1               14   \n",
        "2010-10-06 13:46:01-04:00          17                1               14   \n",
        "2010-10-06 13:12:02-04:00          17                2               13   \n",
        "2010-10-06 13:48:01-04:00          17                1               14   \n",
        "2010-10-06 13:50:02-04:00          17                1               14   \n",
        "\n",
        "                            weather_timestamp        summary precipintensity  \\\n",
        "bikes_timestamp                                                                \n",
        "2010-10-06 12:40:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:44:01-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:52:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:54:01-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:46:01-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:56:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:58:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:42:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:48:02-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 12:50:01-04:00 2010-10-06 16:00:00       Overcast               0   \n",
        "2010-10-06 13:08:02-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:40:01-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:42:02-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:10:01-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:44:02-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:46:01-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:12:02-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:48:01-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "2010-10-06 13:50:02-04:00 2010-10-06 17:00:00  Partly Cloudy               0   \n",
        "\n",
        "                           precipprob preciptype precipaccumulation  \\\n",
        "bikes_timestamp                                                       \n",
        "2010-10-06 12:40:02-04:00           0       None               None   \n",
        "2010-10-06 12:44:01-04:00           0       None               None   \n",
        "2010-10-06 12:52:02-04:00           0       None               None   \n",
        "2010-10-06 12:54:01-04:00           0       None               None   \n",
        "2010-10-06 12:46:01-04:00           0       None               None   \n",
        "2010-10-06 12:56:02-04:00           0       None               None   \n",
        "2010-10-06 12:58:02-04:00           0       None               None   \n",
        "2010-10-06 12:42:02-04:00           0       None               None   \n",
        "2010-10-06 12:48:02-04:00           0       None               None   \n",
        "2010-10-06 12:50:01-04:00           0       None               None   \n",
        "2010-10-06 13:08:02-04:00           0       None               None   \n",
        "2010-10-06 13:40:01-04:00           0       None               None   \n",
        "2010-10-06 13:42:02-04:00           0       None               None   \n",
        "2010-10-06 13:10:01-04:00           0       None               None   \n",
        "2010-10-06 13:44:02-04:00           0       None               None   \n",
        "2010-10-06 13:46:01-04:00           0       None               None   \n",
        "2010-10-06 13:12:02-04:00           0       None               None   \n",
        "2010-10-06 13:48:01-04:00           0       None               None   \n",
        "2010-10-06 13:50:02-04:00           0       None               None   \n",
        "\n",
        "                           temperature  \n",
        "bikes_timestamp                         \n",
        "2010-10-06 12:40:02-04:00        57.48  \n",
        "2010-10-06 12:44:01-04:00        57.48  \n",
        "2010-10-06 12:52:02-04:00        57.48  \n",
        "2010-10-06 12:54:01-04:00        57.48  \n",
        "2010-10-06 12:46:01-04:00        57.48  \n",
        "2010-10-06 12:56:02-04:00        57.48  \n",
        "2010-10-06 12:58:02-04:00        57.48  \n",
        "2010-10-06 12:42:02-04:00        57.48  \n",
        "2010-10-06 12:48:02-04:00        57.48  \n",
        "2010-10-06 12:50:01-04:00        57.48  \n",
        "2010-10-06 13:08:02-04:00        57.90  \n",
        "2010-10-06 13:40:01-04:00        57.90  \n",
        "2010-10-06 13:42:02-04:00        57.90  \n",
        "2010-10-06 13:10:01-04:00        57.90  \n",
        "2010-10-06 13:44:02-04:00        57.90  \n",
        "2010-10-06 13:46:01-04:00        57.90  \n",
        "2010-10-06 13:12:02-04:00        57.90  \n",
        "2010-10-06 13:48:01-04:00        57.90  \n",
        "2010-10-06 13:50:02-04:00        57.90  \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = boston_5_bucketed[np.isfinite(boston_5_bucketed['bikes_available'])]\n",
      "test = test[np.isfinite(test['slots_available'])]\n",
      "print boston_5_bucketed.shape\n",
      "print test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(69051, 3)\n",
        "(47759, 3)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate the percent full \n",
      "#first convert to arrays so that Python doesn't do integer division\n",
      "bikes_available=np.asarray(test[\"bikes_available\"], dtype=np.float32)\n",
      "print bikes_available[0:50]\n",
      "print np.isnan(np.min(bikes_available))\n",
      "slots_available=np.asarray(test[\"slots_available\"], dtype=np.float32)\n",
      "print slots_available[0:50]\n",
      "\n",
      "# Fix for Convergence Issues Using MLE, Option 1: Zero Entries -> 0.01 or Option 2: All Entries += 0.01 (Similar Results)\n",
      "bikes_available[bikes_available == 0] = 0.01\n",
      "slots_available[slots_available == 0] = 0.01\n",
      "\n",
      "#bikes_available = bikes_available+0.01\n",
      "#slots_available = slots_available+0.01\n",
      "\n",
      "# Creating list of [success , failure] outcomes\n",
      "bikes_slots_available=numpy.asarray(zip(bikes_available,slots_available))\n",
      "\n",
      "# Creating Lags of Bike and Slot Variables\n",
      "bikes_available_lag0 = bikes_available[1:]\n",
      "bikes_available_lag1 = bikes_available[0:len(bikes_available)-1]\n",
      "slots_available_lag1 = slots_available[0:len(slots_available)-1]\n",
      "bikes_slots_available = bikes_slots_available[1:]\n",
      "\n",
      "# Calculated the lag-log-odds ratio \n",
      "phat_lag1 = (bikes_available_lag1) / (bikes_available_lag1+slots_available_lag1)\n",
      "\n",
      "logodds_lag1 = log( phat_lag1 / (1-phat_lag1) )\n",
      "\n",
      "\n",
      "# Add Constant to Exogenous Variables\n",
      "logodds_lag1 = sm.add_constant(logodds_lag1, prepend=False)\n",
      "\n",
      "\n",
      "# Fit Binomial Regression.  Coefficients constant in time\n",
      "\n",
      "glm_binom = sm.GLM(bikes_slots_available, logodds_lag1, family=sm.families.Binomial())\n",
      "\n",
      "res = glm_binom.fit()\n",
      "\n",
      "print res.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  0.           0.           0.           0.           0.           0.           0.\n",
        "   0.           0.           0.           0.           0.           0.           0.\n",
        "   0.           0.           0.           0.           0.           0.           0.\n",
        "   2.75         8.4285717    8.           9.          12.375       12.5714283\n",
        "  13.          12.71428585  12.75        13.          13.          13.\n",
        "  12.875       12.          12.          11.85714245  11.          11.5714283\n",
        "  12.          12.          12.          11.14285755  11.          11.          11.\n",
        "  11.          10.125       10.          10.        ]\n",
        "False\n",
        "[ 15.          15.          15.          15.          15.          15.          15.\n",
        "  15.          15.          15.          15.          15.          15.          15.\n",
        "  15.          15.          15.          15.          15.          15.          15.\n",
        "  12.25         6.57142878   7.           6.           2.625        2.42857146\n",
        "   2.           2.28571439   2.25         2.           2.           2.\n",
        "   2.125        3.           3.           3.14285707   4.           3.42857146\n",
        "   3.           3.           3.           3.85714293   4.           4.           4.\n",
        "   4.           4.875        5.           5.        ]\n",
        "                 Generalized Linear Model Regression Results                  \n",
        "==============================================================================\n",
        "Dep. Variable:           ['y1', 'y2']   No. Observations:                47758\n",
        "Model:                            GLM   Df Residuals:                    47756\n",
        "Model Family:                Binomial   Df Model:                            1\n",
        "Link Function:                  logit   Scale:                             1.0\n",
        "Method:                          IRLS   Log-Likelihood:                -64518.\n",
        "Date:                Tue, 16 Jul 2013   Deviance:                       9352.2\n",
        "Time:                        18:33:39   Pearson chi2:                 6.97e+04\n",
        "No. Iterations:                     7                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "x1             0.9531      0.003    309.675      0.000         0.947     0.959\n",
        "const         -0.0011      0.003     -0.393      0.694        -0.007     0.004\n",
        "=============================================================================="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "url = 'http://www.ats.ucla.edu/stat/data/hsb2.csv'\n",
      "hsb2 = pandas.read_table(url, delimiter=\",\")\n",
      "type(hsb2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# question: does DC shut down in the winter?\n",
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "from scipy import stats\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import neighbors\n",
      "from   sklearn.metrics import r2_score\n",
      "import pylab as pl\n",
      "\n",
      "import os\n",
      "import psycopg2\n",
      "import pandas as pd\n",
      "from fetch_station import fetch_station\n",
      "\n",
      "# Fetch all records for a single station (tfl_id == 17 in DC)\n",
      "bike_data_bucketed = fetch_station('Washington, D.C.',17,15, 'max')\n",
      "\n",
      "month = pd.DatetimeIndex(bike_data_bucketed.index).month\n",
      "\n",
      "np.bincount(month)\n",
      "# answer: no, DC is open year round"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([   0, 8875, 8145, 8870, 8626, 8914, 8634, 8089, 6474, 5718, 8169,\n",
        "       8579, 8892])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# goal: join weather data to bike data\n",
      "bike_data_bucketed.head()\n",
      "\n",
      "hour = pd.DatetimeIndex(bike_data_bucketed.index).hour\n",
      "month = pd.DatetimeIndex(bike_data_bucketed.index).month\n",
      "day = pd.DatetimeIndex(bike_data_bucketed.index).day"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city = \"Washington, D.C.\"\n",
      "# Dictionary of timezones\n",
      "timezones = {'Chicago':'US/Central','Boston':'US/Eastern','New York':'US/Eastern','Washington, D.C.':'US/Eastern'}\n",
      "    \n",
      "# Connect to the database\n",
      "conn = psycopg2.connect(\"dbname=\"+os.environ.get('dbname')+\" user=\"+os.environ.get('dbuser')+ \" host=\"+os.environ.get('dburl'))\n",
      "cur = conn.cursor()\n",
      "    \n",
      "# Set timezone\n",
      "timezone = timezones[city]\n",
      "\n",
      "if city == \"Washington, D.C.\":\n",
      "    city = \"washingtondc\"\n",
      "        \n",
      "lower_city = city.lower()\n",
      "\n",
      "# Executes a SQL command\n",
      "# This SQL command selects all rows from the boston database where the station ID is 5\n",
      "cur.execute(\"SELECT * FROM weather_\"+str(lower_city)+\";\")\n",
      "\n",
      "# Fetches all rows in the table output of the SQL query. \n",
      "# Remember to assign to a variable because we can only use fetchall() once for each SQL query.\n",
      "weather = cur.fetchall()\n",
      "# Converts python list of tuples containing data to a pandas dataframe, and renames the columns.\n",
      "\n",
      "# Import data and set index to be timestamp\n",
      "weather_df = pd.DataFrame.from_records(station, columns = [\"station_id\", \"bikes_available\", \"slots_available\", \"timestamp\"], index = [\"timestamp\"])\n",
      "\n",
      "#station_df.index = station_df.index.tz_localize('UTC').tz_convert(timezone)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "x=np.array([1,2,3,4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(4,)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.reshape(len(x), -1).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(4, 1)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dc_17_df[\"weather_timestamp\"] = dc_17_df[\"weather_timestamp\"].tz_localize('UTC').tz_convert(timezone)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dc_17_plus_weather.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'list' object has no attribute 'head'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-532d50a3410e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mdc_17_plus_weather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = [1,2,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.zeros((3, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function from energy team to create matrix of predictors\n",
      "def change_mat(ts, d):\n",
      "    \"\"\"Recieve a time series and a markov delay period.\n",
      "       Return a matix of that design.\"\"\"\n",
      "    n=len(ts)\n",
      "    x = np.array(ts[(d-1):n-1])\n",
      "    for r in range(2,d+1):\n",
      "        b = np.array(ts[(d-r):(n-r)])\n",
      "        x = np.concatenate([x.reshape(len(x),-1),b.reshape(len(b),-1)],axis=1)\n",
      "    return x\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = [1,2,3,4,6,8,10]\n",
      "change_mat(x, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([[3, 2, 1],\n",
        "       [4, 3, 2],\n",
        "       [6, 4, 3],\n",
        "       [8, 6, 4]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.asarray([1,2,3])\n",
      "y = np.asarray([1,1,2])\n",
      "x*y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "array([1, 2, 6])"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}