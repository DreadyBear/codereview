{
 "metadata": {
  "name": "poisson_web(add weather and rebalancing - WD)"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import psycopg2\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import patsy\n",
      "import statsmodels.api as sm\n",
      "import pickle\n",
      "import random\n",
      "import math\n",
      "from datetime import *\n",
      "import pytz\n",
      "from dateutil.relativedelta import *\n",
      "import calendar\n",
      "from calc_non_rebalance_change import calc_non_rebalance_change\n",
      "# from fetch_station import fetch_station\n",
      "\n",
      "conn = psycopg2.connect(\"dbname=\"+os.environ.get('dbname')+\" user=\"+os.environ.get('dbuser')+ \" host=\"+os.environ.get('dburl'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_station_data(station_id, initial_time = datetime(2001,1,1), final_time = datetime(2020,1,1)):\n",
      "    # Pulls Data for Given Station_id and Converts to Pandas Dataframe\n",
      "    cur = conn.cursor()\n",
      "\n",
      "    # Fetch data for station 17 in Washington, DC - 16th & Harvard St NW, terminalName: 31103\n",
      "    cur.execute(\"SELECT * FROM bike_ind_washingtondc WHERE tfl_id = %s;\" % station_id)\n",
      "    station_data = cur.fetchall()\n",
      "\n",
      "    # Put data in pandas dataframe\n",
      "    station_updates = pd.DataFrame.from_records(station_data, columns = [\"station_id\", \"bikes_available\", \"spaces_available\", \"timestamp\"], index = \"timestamp\")\n",
      "\n",
      "    # Convert UTC timezone of the timestamps to DC's Eastern time\n",
      "    station_updates.index = station_updates.index.tz_localize('UTC').tz_convert('US/Eastern')\n",
      "\n",
      "    station_updates = station_updates[str(initial_time):str(final_time)]\n",
      "    return station_updates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_id = '17'\n",
      "total_station_updates = get_station_data(station_id)\n",
      "\n",
      "total_station_updates.head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>station_id</th>\n",
        "      <th>bikes_available</th>\n",
        "      <th>spaces_available</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>timestamp</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2010-10-06 12:38:02-04:00</th>\n",
        "      <td> 17</td>\n",
        "      <td> 3</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2010-10-06 12:40:02-04:00</th>\n",
        "      <td> 17</td>\n",
        "      <td> 3</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2010-10-06 12:42:02-04:00</th>\n",
        "      <td> 17</td>\n",
        "      <td> 3</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2010-10-06 12:44:01-04:00</th>\n",
        "      <td> 17</td>\n",
        "      <td> 3</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2010-10-06 12:46:01-04:00</th>\n",
        "      <td> 17</td>\n",
        "      <td> 3</td>\n",
        "      <td> 12</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "                           station_id  bikes_available  spaces_available\n",
        "timestamp                                                               \n",
        "2010-10-06 12:38:02-04:00          17                3                12\n",
        "2010-10-06 12:40:02-04:00          17                3                12\n",
        "2010-10-06 12:42:02-04:00          17                3                12\n",
        "2010-10-06 12:44:01-04:00          17                3                12\n",
        "2010-10-06 12:46:01-04:00          17                3                12"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_poisson(station_id, include_rebalance = False, initial_time = datetime(2001,1,1), final_time = datetime(2020,1,1)):\n",
      "    # Pull in Data for station_id    \n",
      "    station_updates = get_station_data(station_id, initial_time, final_time)\n",
      "    \n",
      "    # Find changes (deltas) in bike count\n",
      "    bikes_available = station_updates.bikes_available\n",
      "\n",
      "    deltas = bikes_available - bikes_available.shift()\n",
      "\n",
      "    # Show the histogram of the deltas. Need to remove outliers first.\n",
      "    # clipped_deltas = deltas[(deltas > -6) & (deltas < 6)]\n",
      "    # clipped_deltas.hist(bins=11)\n",
      "    \n",
      "    # Include Rebalancing Data and Limit Observations to Windo where Rebalancing Data Exists\n",
      "    time_interval = '1H'\n",
      "    \n",
      "    if (include_rebalance == True):\n",
      "        rebalances = calc_non_rebalance_change(int(station_id), '1H')\n",
      "        rebalances.index = rebalances.index.tz_localize('UTC').tz_convert('US/Eastern')\n",
      "        minimum_rebalance_data = min(rebalances.index)\n",
      "        \n",
      "        # Separate Departure and Arrival of Rebalancing Bikes\n",
      "\n",
      "        pos_adj_for_rebalances = rebalances[rebalances < 0]\n",
      "        neg_adj_for_rebalances = rebalances[rebalances > 0]\n",
      "\n",
      "        pos_deltas = deltas[deltas > 0]\n",
      "        neg_deltas = deltas[deltas < 0]\n",
      "\n",
      "        pos_interval_counts_null = pos_deltas.resample(time_interval, how ='sum')\n",
      "        neg_interval_counts_null = neg_deltas.resample(time_interval, how ='sum')\n",
      "\n",
      "        pos_interval_counts = pos_interval_counts_null.fillna(0)\n",
      "        neg_interval_counts = neg_interval_counts_null.fillna(0)\n",
      "\n",
      "        # Add the Rebalance Data to the Arrival and Departure Data\n",
      "        # Can cause arrivals to become departures and vice versa.\n",
      "\n",
      "        rebalanced_pos_deltas_interval_unadj = pos_interval_counts.add(pos_adj_for_rebalances, fill_value=0)\n",
      "        rebalanced_neg_deltas_interval_unadj = neg_interval_counts.add(neg_adj_for_rebalances, fill_value=0)\n",
      "\n",
      "\n",
      "        # Identify the Cases where rebalance causes aggregate positives to become negative and\n",
      "        # adjust departure numbers.\n",
      "\n",
      "        pos_to_neg_deltas_interval = rebalanced_pos_deltas_interval_unadj[rebalanced_pos_deltas_interval_unadj < 0]\n",
      "        neg_to_pos_deltas_interval = rebalanced_neg_deltas_interval_unadj[rebalanced_neg_deltas_interval_unadj > 0]\n",
      "\n",
      "        # print pos_to_neg_deltas_interval.head()\n",
      "        # print neg_to_pos_deltas_interval.head()\n",
      "\n",
      "        # These are the good cases we want to keep.  We will then match pos-pos and neg-pos into one \n",
      "        # combined vector of all positive deltas.\n",
      "\n",
      "        pos_to_pos_deltas_interval = rebalanced_pos_deltas_interval_unadj[rebalanced_pos_deltas_interval_unadj > 0]\n",
      "        neg_to_neg_deltas_interval = rebalanced_neg_deltas_interval_unadj[rebalanced_neg_deltas_interval_unadj < 0]\n",
      "\n",
      "        rebalanced_pos_deltas_interval_adj = pos_to_pos_deltas_interval.add(neg_to_pos_deltas_interval, fill_value=0)\n",
      "        rebalanced_neg_deltas_interval_adj = neg_to_neg_deltas_interval.add(pos_to_neg_deltas_interval, fill_value=0)\n",
      "\n",
      "        # The adjusted numbers do not contain the hours where we observe zero arrivals or departures\n",
      "        # We use resampling to fix this issue and then fill in the resulting NaN values.\n",
      "\n",
      "        rebalanced_pos_deltas_interval = rebalanced_pos_deltas_interval_adj.resample(time_interval, how ='sum')\n",
      "        rebalanced_neg_deltas_interval = rebalanced_neg_deltas_interval_adj.resample(time_interval, how ='sum')\n",
      "\n",
      "        arrivals = rebalanced_pos_deltas_interval.fillna(0)\n",
      "        departures = abs(rebalanced_neg_deltas_interval.fillna(0))\n",
      "    else:\n",
      "        # If we don't wish to use rebalancing data #\n",
      "        \n",
      "        # Separate positive and negative deltas\n",
      "        pos_deltas = deltas[deltas > 0]\n",
      "        neg_deltas = abs(deltas[deltas < 0])\n",
      "\n",
      "        # Count the number of positive and negative deltas per half hour per day, add them to new dataframe.\n",
      "        pos_interval_counts_null = pos_deltas.resample(time_interval, how ='sum')\n",
      "        neg_interval_counts_null = neg_deltas.resample(time_interval, how ='sum')\n",
      "\n",
      "        # Set NaN delta counts to 0\n",
      "        # By default the resampling step puts NaN (null values) into the data when there were no observations\n",
      "        # to count up during those thirty minutes. \n",
      "        arrivals = pos_interval_counts_null.fillna(0)\n",
      "        departures = neg_interval_counts_null.fillna(0)\n",
      "\n",
      "    arrivals_departures = pd.DataFrame(arrivals, columns=[\"arrivals\"])\n",
      "    arrivals_departures['departures'] = departures\n",
      "    \n",
      "    # Extract months for Month feature, add to model data\n",
      "    delta_months = arrivals_departures.index.month\n",
      "    arrivals_departures['months'] = delta_months\n",
      "\n",
      "    # Extract hours for Hour feature\n",
      "    delta_hours = arrivals_departures.index.hour\n",
      "    arrivals_departures['hours'] = delta_hours\n",
      "\n",
      "    # Extract weekday vs. weekend variable\n",
      "    delta_dayofweek = arrivals_departures.index.weekday\n",
      "\n",
      "    delta_weekday_dummy = delta_dayofweek.copy()\n",
      "    delta_weekday_dummy[delta_dayofweek < 5] = 1\n",
      "    delta_weekday_dummy[delta_dayofweek >= 5] = 0\n",
      "\n",
      "    arrivals_departures['weekday_dummy'] = delta_weekday_dummy\n",
      "\n",
      "    # print arrivals_departures\n",
      "    # print arrivals_departures.head(20)\n",
      "    \n",
      "    # Create design matrix for months, hours, and weekday vs. weekend.\n",
      "    # We can't just create a \"month\" column to toss into our model, because it doesnt\n",
      "    # understand what \"June\" is. Instead, we need to create a column for each month\n",
      "    # and code each row according to what month it's in. Ditto for hours and weekday (=1).\n",
      "    \n",
      "    y_arr, X_arr = patsy.dmatrices(\"arrivals ~ C(months, Treatment) + C(hours, Treatment) + C(weekday_dummy, Treatment)\", arrivals_departures, return_type='dataframe')\n",
      "    y_dep, X_dep = patsy.dmatrices(\"departures ~ C(months, Treatment) + C(hours, Treatment) + C(weekday_dummy, Treatment)\", arrivals_departures, return_type='dataframe')\n",
      "\n",
      "    y_dep[pd.isnull(y_dep)] = 0\n",
      "    \n",
      "    # Fit poisson distributions for arrivals and departures, print results\n",
      "    arr_poisson_model = sm.Poisson(y_arr, X_arr)\n",
      "    arr_poisson_results = arr_poisson_model.fit(disp=0)\n",
      "    \n",
      "    dep_poisson_model = sm.Poisson(y_dep, X_dep)\n",
      "    dep_poisson_results = dep_poisson_model.fit(disp = 0)\n",
      "    \n",
      "    # print arr_poisson_results.summary(), dep_poisson_results.summary()\n",
      "    \n",
      "    poisson_results = [arr_poisson_results, dep_poisson_results]\n",
      "    \n",
      "    return poisson_results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict *net* lambda value some time in the future, using the list of hours created above.\n",
      "# You can predict any number of hours ahead using interval_length, default is set to 1 hour.\n",
      "\n",
      "# The arrival lambda at 12pm actually means the expected arrival rate from 12pm to 1pm. But if the\n",
      "# current time is 12:15pm and you're estimating an hour ahead to 1:15pm, you need to find\n",
      "# 3/4ths of the lambda from 12pm - 1pm and add it to 1/4th of the lambda from 1pm to 2pm.\n",
      "# This section returns the total lambda over that interval, during which the rate is changing.\n",
      "\n",
      "# It also works for predictions multiple hours ahead, as all those lambdas will be summed\n",
      "# and yield a large expected value, which makes sense if you're counting bikes over several hours.\n",
      "\n",
      "# The function predicts arrival lambdas across the time interval, does the same thing independently\n",
      "# for departure lambdas, and finds their difference to get the net lambda at that time - the change in bikes\n",
      "# you'll see at the station in an hour. Add the net lambda to the current number of bikes to get\n",
      "# the prediction of the expected value of how many bikes will be there.\n",
      "\n",
      "def lambda_calc(month, time, weekday, poisson_results):\n",
      "    \"Compute the lambda value for a specific month, time (hour), and weekday.\"\n",
      "        \n",
      "    # Pull out coefficient estimates for the factored covariants\n",
      "    #estimates = poisson_results[\"params\"]\n",
      "    estimates = poisson_results.params\n",
      "    \n",
      "    # Fetch intercept\n",
      "    intercept = estimates['Intercept']\n",
      "        \n",
      "    # Fetch coefficient estimate that corresponds to the month..\n",
      "    if month == 1:\n",
      "        month_estimate = 0\n",
      "    else:\n",
      "        month_estimate = estimates['C(months, Treatment)[T.'+str(month)+']']\n",
      "    \n",
      "    # .. to the hour\n",
      "    hour = floor(time)\n",
      "    if (hour == 0) or (hour == 24):\n",
      "        hour_estimate = 0\n",
      "    else:\n",
      "       hour_estimate = estimates['C(hours, Treatment)[T.'+str(int(hour))+']']\n",
      "    \n",
      "    # .. and to the weekday status.\n",
      "    if weekday == 0:\n",
      "        weekday_estimate = 0\n",
      "    else:\n",
      "        weekday_estimate = estimates['C(weekday_dummy, Treatment)[T.'+str(weekday)+']']\n",
      "    \n",
      "    # Compute log lambda, which is linear function of the hour, month, and weekday coefficient estimates\n",
      "    log_lambda = intercept + month_estimate + hour_estimate + weekday_estimate\n",
      "        \n",
      "    # Raise e to the computed log lambda to find the estimated value of the Poisson distribution for these covariates.\n",
      "    est_lambda = exp(log_lambda)\n",
      "        \n",
      "    return est_lambda\n",
      "    \n",
      "\n",
      "def predict_net_lambda(current_time, prediction_interval, month, weekday, poisson_results):\n",
      "    \n",
      "    # Define function that takes in a month, time, weekday and returns \n",
      "    # a lambda - the expected value of arrivals or departures during that hour (given that month)\n",
      "    # - using the covariate coefficients estimated above.\n",
      "    \n",
      "    # Create list of hours in between the current time and the prediction time\n",
      "    # Need to do this to calculate cumulative rate of arrivals and departures\n",
      "    prediction_time = current_time + prediction_interval\n",
      "\n",
      "    time_list = [current_time]\n",
      "    next_step = current_time\n",
      "    while next_step != prediction_time:\n",
      "    \n",
      "        if floor(next_step) + 1 < prediction_time:\n",
      "            next_step = floor(next_step) + 1\n",
      "            time_list.append(next_step)\n",
      "        \n",
      "        else:\n",
      "            next_step = prediction_time\n",
      "            time_list.append(next_step)\n",
      "        \n",
      "    \n",
      "    # Calculate the cumulative lambda rate over the predition interval\n",
      "    arr_cum_lambda = 0 \n",
      "    dep_cum_lambda = 0 \n",
      "    \n",
      "    # Find cumulative lambda for arrivals..\n",
      "    for i in range(1, len(time_list)):\n",
      "        est_lambda = lambda_calc(month, time_list[ i - 1 ], weekday, poisson_results[0])\n",
      "        hour_proportion = time_list[i] - time_list[ i - 1 ]\n",
      "    \n",
      "        interval_lambda = est_lambda * hour_proportion\n",
      "        \n",
      "        arr_cum_lambda += interval_lambda\n",
      "        \n",
      "    # .. and departures\n",
      "    for i in range(1, len(time_list)):\n",
      "        est_lambda = lambda_calc(month, time_list[ i - 1 ], weekday, poisson_results[1])\n",
      "        hour_proportion = time_list[i] - time_list[ i - 1 ]\n",
      "    \n",
      "        interval_lambda = est_lambda * hour_proportion\n",
      "        \n",
      "        dep_cum_lambda += interval_lambda\n",
      "    \n",
      "    net_lambda = arr_cum_lambda - dep_cum_lambda\n",
      "    \n",
      "    return net_lambda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_with_rebalance = fit_poisson('17', True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_no_rebalance = fit_poisson('17', False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Compare the Results of Rebalance and Balance Poisson Results\n",
      "hours = range(0,24)\n",
      "months = range(1,13)\n",
      "weeks = range(0,2)\n",
      "\n",
      "for month in months:\n",
      "    for time in hours:\n",
      "        for weekday in weeks:\n",
      "            \n",
      "            on_diff = abs(lambda_calc(month, time, weekday, results_no_rebalance[0]) - lambda_calc(month, time, weekday, results_with_rebalance[0]))\n",
      "            \n",
      "            off_diff = abs(lambda_calc(month, time, weekday, results_no_rebalance[1]) - lambda_calc(month, time, weekday, results_with_rebalance[1]))\n",
      "            \n",
      "            if max(on_diff, off_diff) > 1.5:\n",
      "                print \"Month: \", month, \"Hour:\", time, \"Weeks :\", weekday"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Month:  4 Hour: 5 Weeks : 0\n",
        "Month:  4 Hour: 17 Weeks : 0\n",
        "Month:  5 Hour: 5 Weeks : 0\n",
        "Month: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5 Hour: 17 Weeks : 0\n",
        "Month:  6 Hour: 5 Weeks : 0\n",
        "Month:  6 Hour: 17 Weeks : 0\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Estimate the poisson!\n",
      "def save_poisson_results(include_rebalance = False):\n",
      "    station_ids = distinctIds()\n",
      "    # station_ids = distinctIds()[:1]\n",
      "    for station_id in station_ids:\n",
      "        poisson_results = fit_poisson(station_id, include_rebalance)\n",
      "        file_out = open(\"/mnt/data1/BikeShare/pickles/poisson_results_%s.p\" % station_id, \"wb\")\n",
      "        to_save_ps = (poisson_results[0].params, poisson_results[1].params)\n",
      "        pickle.dump(to_save_ps, file_out)\n",
      "        file_out.close()\n",
      "        print \"did %s\" % station_id\n",
      "save_poisson_results()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 11218.536146\n",
        "         Iterations 11\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 10796.887888\n",
        "         Iterations 10\n",
        "did 1\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 19420.957554\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 19768.473962\n",
        "         Iterations 10\n",
        "did 2\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 20502.445646\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 22153.466785\n",
        "         Iterations 10\n",
        "did 3\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 17330.313800\n",
        "         Iterations 9\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 17080.244095\n",
        "         Iterations 10\n",
        "did 4\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 12858.336226\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 12868.490297\n",
        "         Iterations 11\n",
        "did 5\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 14027.757994\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 14623.737411\n",
        "         Iterations 9\n",
        "did 6\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 18880.857629\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 18980.330289\n",
        "         Iterations 10\n",
        "did 7\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 34669.926415\n",
        "         Iterations 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 32042.680432\n",
        "         Iterations 9\n",
        "did 8\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 17123.120346\n",
        "         Iterations 9\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 17624.943321\n",
        "         Iterations 10\n",
        "did 9\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 24195.914813\n",
        "         Iterations 9\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 24279.941913\n",
        "         Iterations 10\n",
        "did 10\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 20726.652484\n",
        "         Iterations 9\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 22422.834034\n",
        "         Iterations 10\n",
        "did 11\n",
        "Optimization terminated successfully."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         Current function value: 21913.917240\n",
        "         Iterations 9\n",
        "Optimization terminated successfully."
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_poisson_result(station_id):\n",
      "    temp = pickle.load(open(\"/mnt/data1/BikeShare/pickles/poisson_results_%s.p\" % station_id, \"rb\"))\n",
      "    return (dict(params=temp[0]), dict(params=temp[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "'''\n",
      "# Auxiliary code\n",
      "# Try to predict!\n",
      "current_time = 17.5\n",
      "prediction_interval = 1\n",
      "month = 5\n",
      "weekday = 0\n",
      "\n",
      "bike_change = predict_net_lambda(current_time, prediction_interval, month, weekday, poisson_results)\n",
      "# print \"The change in bikes at time %s and month %s is %s\" % (str(floor(current_time)), str(month), str(bike_change))\n",
      "\n",
      "# Plot predictions of available bikes by hour for given covariates\n",
      "init_bikes = 18\n",
      "bike = init_bikes\n",
      "bikes = [init_bikes]\n",
      "hours_of_day  = range(1,24)\n",
      "\n",
      "for hour in hours_of_day:\n",
      "    bike += predict_net_lambda(hour, prediction_interval, month, weekday, poisson_results)\n",
      "    bikes.append(bike)\n",
      "       \n",
      "pd.Series(bikes).plot()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "'\\n# Auxiliary code\\n# Try to predict!\\ncurrent_time = 17.5\\nprediction_interval = 1\\nmonth = 5\\nweekday = 0\\n\\nbike_change = predict_net_lambda(current_time, prediction_interval, month, weekday, poisson_results)\\n# print \"The change in bikes at time %s and month %s is %s\" % (str(floor(current_time)), str(month), str(bike_change))\\n\\n# Plot predictions of available bikes by hour for given covariates\\ninit_bikes = 18\\nbike = init_bikes\\nbikes = [init_bikes]\\nhours_of_day  = range(1,24)\\n\\nfor hour in hours_of_day:\\n    bike += predict_net_lambda(hour, prediction_interval, month, weekday, poisson_results)\\n    bikes.append(bike)\\n       \\npd.Series(bikes).plot()\\n'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simulate bike availability at station 17 for next half hour\n",
      "\n",
      "# We're doing this to flag when station is full or empty, which\n",
      "# is what bikeshare operators want.\n",
      "\n",
      "#import sys \n",
      "\n",
      "def simulate_bikes(station_id, starting_time, final_time, max_slots, starting_bikes_available, month, weekday, poisson_results):\n",
      "    bikes_available = starting_bikes_available\n",
      "    current_time = starting_time\n",
      "    go_empty = 0\n",
      "    go_full = 0\n",
      "    while current_time < final_time:\n",
      "        # Calculate the Appropriate Up and Down Rate Terms\n",
      "\t\tup_lambda = lambda_calc(month,current_time,weekday, poisson_results[0])\n",
      "\t\tdown_lambda = lambda_calc(month,current_time,weekday, poisson_results[1])\n",
      "\t\ttotal_lambda = float(up_lambda + down_lambda)\n",
      "\n",
      "\t\tnext_obs_time = random.expovariate(total_lambda)\n",
      "\t\tchance_up = up_lambda / total_lambda\n",
      "\n",
      "\t\t# Update the Current Time to the Next Observation Time\n",
      "\t\tcurrent_time += next_obs_time\t\t\n",
      "\n",
      "\t\tif current_time < final_time:\n",
      "\n",
      "\t\t\tif random.uniform(0,1) > chance_up:\n",
      "\t\t\t\tbikes_available -= 1\n",
      "\t\t\telse:\n",
      "\t\t\t\tbikes_available += 1\n",
      "\n",
      "\t\t# Adjust Bikes Available to Sit Inside Range\n",
      "\t\tif bikes_available < 0:\n",
      "\t\t\tbikes_available = 0\n",
      "\t\telif bikes_available > max_slots:\n",
      "\t\t\tbikes_available = max_slots\n",
      "\n",
      "\t\tif bikes_available == 0:\n",
      "\t\t\tgo_empty = 1\n",
      "\t\tif bikes_available == max_slots:\n",
      "\t\t\tgo_full = 1\n",
      "\n",
      "    return (bikes_available, go_empty, go_full)\n",
      "\n",
      "\n",
      "def simulation(station_id, starting_time, final_time, max_slots, starting_bikes_available, month, weekday, simulate_bikes, trials=250):\n",
      "    poisson_results = load_poisson_result(station_id)\n",
      "    bikes_results = [] # numbikes at the station at the end of each trial\n",
      "    go_empty_results = [] #\n",
      "    go_full_results = [] #\n",
      "    for i in range(1,trials):\n",
      "\t\tbikes, empty, full = simulate_bikes(station_id, starting_time,final_time,max_slots,starting_bikes_available,month,weekday, poisson_results)\n",
      "\t\tbikes_results.append(bikes)\n",
      "\t\tgo_empty_results.append(empty)\n",
      "\t\tgo_full_results.append(full)\n",
      "    return (bikes_results, go_empty_results, go_full_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_prediction(station_id, how_many_mins):\n",
      "    starting_datetime = datetime.now(pytz.timezone('US/Eastern'))\n",
      "    ending_datetime = starting_datetime + relativedelta(minutes=how_many_mins)\n",
      "\n",
      "    \n",
      "    # protect sql injection later?\n",
      "    cur = conn.cursor()\n",
      "    cur.execute(\"select * from bike_ind_washingtondc where tfl_id = %s order by timestamp desc limit 1;\" % station_id)\n",
      "    _, starting_bikes_available, num_spaces, _  = cur.fetchall()[0] #(station_id, bikes, spaces, timestamp)\n",
      "    \n",
      "    max_slots = starting_bikes_available + num_spaces\n",
      "    \n",
      "    month = starting_datetime.month # Between 1-12\n",
      "    \n",
      "    weekday = 0\n",
      "    if (starting_datetime.isoweekday == 0) or (starting_datetime.isoweekday == 7):\n",
      "        weekday = 1\n",
      "    \n",
      "    starting_time = round(starting_datetime.hour + (starting_datetime.minute / float(60)), 3)\n",
      "    ending_time = round(ending_datetime.hour + (ending_datetime.minute / float(60)), 3)\n",
      "    \n",
      "    bikes_results, empty_results, full_results = simulation(station_id, starting_time, ending_time, max_slots, \\\n",
      "        starting_bikes_available, month, weekday, simulate_bikes, 500)\n",
      "    \n",
      "    week_dict = {'0': 'Week', '1' : 'Weekend'}\n",
      "\n",
      "    # net_lambda = predict_net_lambda(starting_time, final_time - starting_time, month, weekday, poisson_results)\n",
      "    \n",
      "    print (\"In %s during the %s\" % (calendar.month_name[month], week_dict[str(weekday)]))\n",
      "    print (\"For Starting Time: %0.2f and Ending Time: %0.2f with Initial Bikes: %d out of a Maximum: %d\" % (starting_time, ending_time, starting_bikes_available, max_slots))\n",
      "    print ('Expected Number of Bikes at %s: %0.2f' % (ending_time, round(np.mean(bikes_results),2)))\n",
      "    # print 'Other Expected Value : ', starting_bikes_available + net_lambda\n",
      "    print ('Probability of Being (Empty, Full) Any Time in the Next %0.2f hours: (%0.2f, %0.2f)' % \\\n",
      "        (ending_time - starting_time, round(np.mean(empty_results),2), round(np.mean(full_results),2)))\n",
      "    return\n",
      "\n",
      "%time make_prediction('17', 15*4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "In August during the Week\n",
        "For Starting Time: 11.82 and Ending Time: 12.82 with Initial Bikes: 0 out of a Maximum: 32\n",
        "Expected Number of Bikes at 12.817: 1.36\n",
        "Probability of Being (Empty, Full) Any Time in the Next 1.00 hours: (0.86, 0.00)\n",
        "CPU times: user 0.28 s, sys: 0.00 s, total: 0.28 s\n",
        "Wall time: 0.28 s\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_code():\n",
      "    \n",
      "    starting_time = 6.0\n",
      "    final_time = 6.5\n",
      "    starting_bikes_available = 21\n",
      "    max_slots = 25\n",
      "    \n",
      "    month = 8\n",
      "    weekday = 0\n",
      "    \n",
      "    station_id = '17'\n",
      "\n",
      "    #starting_time, final_time, max_slots, starting_bikes_available, month, weekday,\n",
      "    \n",
      "    bikes_results, empty_results, full_results = simulation(station_id, starting_time, final_time, max_slots, starting_bikes_available, \\\n",
      "        month, weekday,simulate_bikes, 500)\n",
      "    \n",
      "    expected_num_bikes = round(np.mean(bikes_results), 2)\n",
      "    prob_empty_any_time = round(np.mean(empty_results), 2)\n",
      "    prob_full_any_time = round(np.mean(full_results), 2)\n",
      "    \n",
      "    #print (expected_num_bikes, prob_empty_any_time, prob_full_any_time)\n",
      "    \n",
      "%timeit run_code()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 65.7 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def distinctIds():\n",
      "    cur = conn.cursor()\n",
      "    cur.execute(\"SELECT DISTINCT id FROM metadata_washingtondc order by id;\")\n",
      "    station_ids = cur.fetchall()\n",
      "\n",
      "    station_list = []\n",
      "    for station in station_ids:\n",
      "        station_list.append(station[0])\n",
      "        \n",
      "    return station_list\n",
      "print distinctIds()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def validation_simulation(station_id, starting_time, final_time, max_slots, starting_bikes_available, month, weekday, poisson_results, trials=250):\n",
      "    bikes_results = [] # numbikes at the station at the end of each trial\n",
      "    go_empty_results = [] #\n",
      "    go_full_results = [] #\n",
      "    for i in range(1,trials):\n",
      "\t\tbikes, empty, full = simulate_bikes(station_id, starting_time,final_time,max_slots,starting_bikes_available,month,weekday, poisson_results)\n",
      "\t\tbikes_results.append(bikes)\n",
      "\t\tgo_empty_results.append(empty)\n",
      "\t\tgo_full_results.append(full)\n",
      "    return (bikes_results, go_empty_results, go_full_results)\n",
      "\n",
      "def station_updates_until_time(time, total_station_updates):\n",
      "    station_updates = total_station_updates[:str(time)]\n",
      "    return station_updates\n",
      "\n",
      "def empty_in_window(starting_time, ending_time, total_station_updates):\n",
      "    go_empty = 0\n",
      "    bikes_available_in_window = total_station_updates['bikes_available'][str(starting_time):str(ending_time)]\n",
      "    return int(any(bikes_available_in_window==0))\n",
      "\n",
      "def bikes_at_time(time, total_station_updates):\n",
      "    bikes_available_up_to_time = total_station_updates['bikes_available'][str(time):]\n",
      "    return bikes_available_up_to_time[0]\n",
      "\n",
      "def mse_calculation(min_time_pt, last_time, months_time_step, days_time_step, hours_time_step, prediction_interval, total_station_updates):\n",
      "    time = min_time_pt\n",
      "    SE = 0\n",
      "    SE_IND = 0\n",
      "    num_comps = 1\n",
      "    while time < last_time:\n",
      "        poisson_results_validation = fit_poisson(station_updates_until_time(time, total_station_updates))\n",
      "        \n",
      "        converted_time = round(time.hour + (time.minute / float(60)), 3)\n",
      "        final_time = time + relativedelta(hours = prediction_interval)\n",
      "        converted_final_time = round(final_time.hour + (final_time.minute / float(60)), 3)\n",
      "        \n",
      "        max_slots = 25\n",
      "        month = time.month\n",
      "        weekday = 0\n",
      "        if (time.isoweekday == 0) or (time.isoweekday == 7):\n",
      "            weekday = 1\n",
      "        \n",
      "        starting_bikes_available = bikes_at_time(time, total_station_updates)\n",
      "        \n",
      "        bikes_results, empty_results, full_results = validation_simulation(station_id, converted_time, converted_final_time,  max_slots, starting_bikes_available, month, weekday, poisson_results_validation, 250)\n",
      "        \n",
      "        expected_bikes = np.mean(bikes_results)\n",
      "        prob_empty = np.mean(empty_results)\n",
      "        \n",
      "        SE += (expected_bikes - float(bikes_at_time(final_time, total_station_updates)))**2\n",
      "        SE_IND += (prob_empty - empty_in_window(time, final_time, total_station_updates))**2\n",
      "        \n",
      "        time += relativedelta(months = months_time_step, days = days_time_step, hours = hours_time_step)\n",
      "        num_comps += 1\n",
      "    \n",
      "    MSE = SE / num_comps\n",
      "    MSE_IND = SE_IND / num_comps\n",
      "    \n",
      "    return (MSE, MSE_IND)\n",
      "\n",
      "#print total_station_updates.index[-1]\n",
      "\n",
      "last_time = datetime(2013, 7, 1, 12,0,0)\n",
      "\n",
      "# Validate the model!\n",
      "min_time_pt = datetime(2011, 10, 7,12,38,2)\n",
      "\n",
      "months_time_step = 0 # number of months time step\n",
      "days_time_step = 7 # number of days time step\n",
      "hours_time_step = 1 # number of hours time step\n",
      "\n",
      "preds = [0.25, 0.5, 0.75, 1.0, 2.0] # Number of Hours Out We Want to Predict\n",
      "mse_results = []\n",
      "mse_ind_results = []\n",
      "\n",
      "for prediction_interval in preds:\n",
      "    mse, mse_ind = mse_calculation(min_time_pt, last_time, months_time_step, days_time_step, hours_time_step, prediction_interval, total_station_updates)\n",
      "    \n",
      "    mse_results.append(mse)\n",
      "    mse_ind_results.append(mse_ind)\n",
      "    \n",
      "print mse_results\n",
      "\n",
      "print mse_ind_results\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print map(math.sqrt,mse_results)\n",
      "\n",
      "print map(math.sqrt, mse_ind_results)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2.8113476745442516, 3.6852584359638754, 4.828661545710887, 5.271443628986439, 6.084578374750701]\n",
        "[0.2040540077924463, 0.21915764211090463, 0.2559851139705962, 0.31166605795586255, 0.38067755987219487]\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}