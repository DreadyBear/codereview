{
 "metadata": {
  "name": "AR_Model_Validation_to_match_Adam's"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "from scipy import stats\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "import os\n",
      "import psycopg2\n",
      "import pandas as pd\n",
      "from fetch_station import fetch_station\n",
      "\n",
      "# Fetch all records for a single station (tfl_id == 5)\n",
      "data_bucketed = fetch_station('Washington, D.C.',24,16, 'max')\n",
      "\n",
      "# Calculate the percent full \n",
      "#first convert to arrays so that Python doesn't do integer division\n",
      "bikes_available=np.asarray(data_bucketed[\"bikes_available\"], dtype=np.float32)\n",
      "slots_available=np.asarray(data_bucketed[\"slots_available\"], dtype=np.float32)\n",
      "\n",
      "# Fix for Convergence Issues Using MLE, Option 1: Zero Entries -> 0.01 or Option 2: All Entries += 0.01 (Similar Results)\n",
      "bikes_available[bikes_available == 0] = 0.01\n",
      "slots_available[slots_available == 0] = 0.01\n",
      "\n",
      "#bikes_available = bikes_available+0.01\n",
      "#slots_available = slots_available+0.01\n",
      "\n",
      "# Creating list of [success , failure] outcomes\n",
      "bikes_slots_available=np.asarray(zip(bikes_available,slots_available))\n",
      "\n",
      "# create log odds ratio of bikes to slots\n",
      "phat = bikes_available / (bikes_available + slots_available) \n",
      "logodds = np.log(phat/(1-phat))\n",
      "\n",
      "# Creating Lags of Bike and Slot Variables\n",
      "bikes_available_lag0 = bikes_available[1:]\n",
      "bikes_available_lag1 = bikes_available[0:len(bikes_available)-1]\n",
      "slots_available_lag1 = slots_available[0:len(slots_available)-1]\n",
      "bikes_slots_available_lag1 = bikes_slots_available[1:]\n",
      "\n",
      "# Calculated the lag-log-odds ratio \n",
      "phat_lag1 = (bikes_available_lag1) / (bikes_available_lag1+slots_available_lag1)\n",
      "#print \"phat_lag1\" + str(phat_lag1)\n",
      "#print len(phat_lag1)\n",
      "\n",
      "logodds_lag1 = np.log( phat_lag1 / (1-phat_lag1) )\n",
      "\n",
      "# function for creating lagged variables\n",
      "def change_mat(ts, binom, d):\n",
      "    \"\"\"Recieve a time series and a markov delay period.\n",
      "       Return a matix of that design.\"\"\"\n",
      "    n=len(ts)\n",
      "    x = np.array(ts[(d-1):n-1])\n",
      "    for r in range(2,d+1):\n",
      "        b = np.array(ts[(d-r):(n-r)])\n",
      "        x = np.concatenate([x.reshape(len(x),-1),b.reshape(len(b),-1)],axis=1)\n",
      "    y = binom[d:]\n",
      "    return x, y\n",
      "\n",
      "# run function to create prediction and outcome variables\n",
      "pred_ar3, outcome_ar3 = change_mat(logodds, bikes_slots_available, 3)\n",
      "\n",
      "# Add Constant to Exogenous Variables\n",
      "logodds_lag1_cons = sm.add_constant(logodds_lag1, prepend=False)\n",
      "\n",
      "# create model based on first 80% of data\n",
      "num_train = 4*len(logodds) // 5\n",
      "\n",
      "\n",
      "# Fit Binomial Regression.  Coefficients constant in time\n",
      "\n",
      "glm_ar3 = sm.GLM(outcome_ar3[:num_train], pred_ar3[:num_train], family=sm.families.Binomial())\n",
      "\n",
      "results = glm_ar3.fit()\n",
      "\n",
      "print results.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "                 Generalized Linear Model Regression Results                  \n",
        "==============================================================================\n",
        "Dep. Variable:           ['y1', 'y2']   No. Observations:                72927\n",
        "Model:                            GLM   Df Residuals:                    72924\n",
        "Model Family:                Binomial   Df Model:                            2\n",
        "Link Function:                  logit   Scale:                             1.0\n",
        "Method:                          IRLS   Log-Likelihood:            -1.3460e+05\n",
        "Date:                Mon, 29 Jul 2013   Deviance:                       75662.\n",
        "Time:                        17:16:03   Pearson chi2:                 4.03e+05\n",
        "No. Iterations:                    15                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "x1             0.8016      0.003    242.402      0.000         0.795     0.808\n",
        "x2            -0.0405      0.003    -13.996      0.000        -0.046    -0.035\n",
        "x3             0.0376      0.002     17.492      0.000         0.033     0.042\n",
        "=============================================================================="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict on test data (last 20% of the observations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run model with more predictors so that we can test the generalized code below\n",
      "\n",
      "# This model includes month effects and one previous time point\n",
      "##### previous time point is very significant predictor; months are not\n",
      "\n",
      "import datetime\n",
      "import patsy\n",
      "from patsy.contrasts import Treatment\n",
      "\n",
      "# Set up data frame with one lagged time point and a constant\n",
      "data = pd.DataFrame(logodds_lag1, columns = [\"logodds_lag1\", \"constant\"])\n",
      "\n",
      "# Strip month information from original timestamp variable\n",
      "month = pd.DatetimeIndex(data_bucketed.index).month\n",
      "\n",
      "# Month as a factor variable\n",
      "# Method 1 - doesn't work\n",
      "# Month =pd.Factor(month[1:]-1, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
      "\n",
      "# Method 2- doesn't work\n",
      "#month = pd.Categorical.from_array(month[1:])\n",
      "#print patsy.dmatrix('month')\n",
      "\n",
      "#method 3\n",
      "levels = [3,4,5,6,7,8,9,10,11,12]\n",
      "contrast = Treatment(reference=0).code_without_intercept(levels)\n",
      "print contrast.matrix\n",
      "month_dummy = contrast.matrix[month-3, :]\n",
      "\n",
      "#drop first row because of lagged variable\n",
      "month_dummy = month_dummy[1:, :]\n",
      "\n",
      "#feel free to try to make this work... bree ran out of patience and did it the ugly way below\n",
      "#month_dummy.dtype.names = ('Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec')\n",
      "#data['Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'] = month_dummy[:,0:11]\n",
      "\n",
      "#add dummy variables to dataset, using March as a reference variable.  do not add Jan or Feb because there are no observations in these months\n",
      "data['jul'] = month_dummy[:,3]\n",
      "data['aug'] = month_dummy[:,4]\n",
      "data['sep'] = month_dummy[:,5]\n",
      "data['oct'] = month_dummy[:,6]\n",
      "data['nov'] = month_dummy[:,7]\n",
      "data['dec'] = month_dummy[:,8]\n",
      "data['apr'] = month_dummy[:,0]\n",
      "data['may'] = month_dummy[:,1]\n",
      "data['jun'] = month_dummy[:,2]\n",
      "\n",
      "print data[1:10]\n",
      "#run model\n",
      "glm_binom_2 = sm.GLM(bikes_slots_available, data, family=sm.families.Binomial())\n",
      "\n",
      "results = glm_binom_2.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}